<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Text Editor V5 - Hybrid Auto-Detection</title>

    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>
    <script async src="https://docs.opencv.org/4.8.0/opencv.js"></script>

    <style>
        body { background-color: #0f172a; color: #f8fafc; font-family: 'Inter', sans-serif; margin: 0; }
        .animate-pulse { animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: .5; } }
        .animate-spin { animation: spin 1s linear infinite; }
        @keyframes spin { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useRef, useEffect, useCallback } = React;

        // ==================== PREPROCESSING ====================
        const preprocessImageForOCR = (canvas) => {
            return new Promise((resolve) => {
                if (typeof cv === 'undefined') {
                    resolve(canvas.toDataURL());
                    return;
                }

                let src, gray, bilateral, enhanced, blurred, sharpened, binary;
                let kernel1, opened, kernel2, closed, padded, rgba;

                try {
                    const ctx = canvas.getContext('2d');
                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                    src = cv.matFromImageData(imageData);

                    // Upscale if too small
                    if (src.cols < 200 || src.rows < 60) {
                        const scale = Math.max(200 / src.cols, 60 / src.rows, 2.0);
                        const upscaled = new cv.Mat();
                        const dsize = new cv.Size(src.cols * scale, src.rows * scale);
                        cv.resize(src, upscaled, dsize, 0, 0, cv.INTER_CUBIC);
                        src.delete();
                        src = upscaled;
                    }

                    gray = new cv.Mat();
                    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

                    bilateral = new cv.Mat();
                    cv.bilateralFilter(gray, bilateral, 9, 75, 75);

                    const clahe = new cv.CLAHE(2.0, new cv.Size(8, 8));
                    enhanced = new cv.Mat();
                    clahe.apply(bilateral, enhanced);

                    blurred = new cv.Mat();
                    cv.GaussianBlur(enhanced, blurred, new cv.Size(0, 0), 3);
                    sharpened = new cv.Mat();
                    cv.addWeighted(enhanced, 1.5, blurred, -0.5, 0, sharpened);

                    binary = new cv.Mat();
                    cv.threshold(sharpened, binary, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU);

                    kernel1 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(1, 1));
                    opened = new cv.Mat();
                    cv.morphologyEx(binary, opened, cv.MORPH_OPEN, kernel1);

                    kernel2 = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(2, 2));
                    closed = new cv.Mat();
                    cv.morphologyEx(opened, closed, cv.MORPH_CLOSE, kernel2);

                    padded = new cv.Mat();
                    cv.copyMakeBorder(closed, padded, 10, 10, 10, 10, cv.BORDER_CONSTANT, new cv.Scalar(255, 255, 255, 255));

                    rgba = new cv.Mat();
                    cv.cvtColor(padded, rgba, cv.COLOR_GRAY2RGBA);

                    const resultCanvas = document.createElement('canvas');
                    resultCanvas.width = rgba.cols;
                    resultCanvas.height = rgba.rows;
                    const resultCtx = resultCanvas.getContext('2d');
                    const resultImageData = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
                    resultCtx.putImageData(resultImageData, 0, 0);

                    resolve(resultCanvas.toDataURL());
                } catch (error) {
                    console.error('Preprocessing error:', error);
                    resolve(canvas.toDataURL());
                } finally {
                    if (src) src.delete();
                    if (gray) gray.delete();
                    if (bilateral) bilateral.delete();
                    if (enhanced) enhanced.delete();
                    if (blurred) blurred.delete();
                    if (sharpened) sharpened.delete();
                    if (binary) binary.delete();
                    if (kernel1) kernel1.delete();
                    if (opened) opened.delete();
                    if (kernel2) kernel2.delete();
                    if (closed) closed.delete();
                    if (padded) padded.delete();
                    if (rgba) rgba.delete();
                }
            });
        };

        // ==================== POST-PROCESSING ====================
        const postProcessOCRText = (text) => {
            if (!text) return '';
            let cleaned = text.replace(/\s+/g, ' ');

            cleaned = cleaned.replace(/([a-zA-Z])0([a-zA-Z])/g, '$1O$2');
            cleaned = cleaned.replace(/([a-zA-Z])1([a-zA-Z])/g, '$1l$2');
            cleaned = cleaned.replace(/([a-zA-Z])5([a-zA-Z])/g, '$1S$2');
            cleaned = cleaned.replace(/([a-zA-Z])8([a-zA-Z])/g, '$1B$2');
            cleaned = cleaned.replace(/([a-zA-Z])\|([a-zA-Z])/g, '$1I$2');

            const wordFixes = {
                'tlie': 'the', 'Tlie': 'The', 'witli': 'with', 'Witli': 'With',
                'wliich': 'which', 'Wliich': 'Which', 'wliat': 'what', 'Wliat': 'What',
                'tliat': 'that', 'Tliat': 'That', 'liave': 'have', 'Liave': 'Have',
                'tliis': 'this', 'Tliis': 'This'
            };

            Object.entries(wordFixes).forEach(([wrong, right]) => {
                const regex = new RegExp('\\b' + wrong + '\\b', 'g');
                cleaned = cleaned.replace(regex, right);
            });

            if (cleaned.length > 0 && /^[a-z]/.test(cleaned)) {
                cleaned = cleaned.charAt(0).toUpperCase() + cleaned.slice(1);
            }

            cleaned = cleaned.replace(/^[,.\-:;]+/, '').replace(/[,.\-:;]+$/, '');
            return cleaned.trim();
        };

        // ==================== AUTO TEXT DETECTION ====================
        const autoDetectTextRegions = (canvas, cvReady) => {
            return new Promise((resolve) => {
                if (!cvReady || typeof cv === 'undefined') {
                    console.warn('OpenCV not ready, skipping auto-detection');
                    resolve([]);
                    return;
                }

                try {
                    const ctx = canvas.getContext('2d');
                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

                    const src = cv.matFromImageData(imageData);
                    const gray = new cv.Mat();
                    const binary = new cv.Mat();
                    const morph = new cv.Mat();
                    const dilated = new cv.Mat();

                    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

                    cv.adaptiveThreshold(gray, binary, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 15, 10);

                    const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(20, 3));
                    cv.morphologyEx(binary, morph, cv.MORPH_CLOSE, kernel);

                    const dilateKernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(10, 5));
                    cv.dilate(morph, dilated, dilateKernel);

                    const contours = new cv.MatVector();
                    const hierarchy = new cv.Mat();
                    cv.findContours(dilated, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

                    const detectedRegions = [];
                    const minArea = 500;
                    const maxArea = (canvas.width * canvas.height) * 0.8;
                    const minAspectRatio = 1.5;

                    for (let i = 0; i < contours.size(); i++) {
                        const contour = contours.get(i);
                        const rect = cv.boundingRect(contour);
                        const area = rect.width * rect.height;
                        const aspectRatio = rect.width / rect.height;

                        if (area >= minArea && area <= maxArea && aspectRatio >= minAspectRatio &&
                            rect.width > 50 && rect.height > 15 && rect.height < canvas.height * 0.5) {
                            const padding = 10;
                            detectedRegions.push({
                                id: i,
                                x: Math.max(0, rect.x - padding),
                                y: Math.max(0, rect.y - padding),
                                width: Math.min(canvas.width - rect.x + padding, rect.width + padding * 2),
                                height: Math.min(canvas.height - rect.y + padding, rect.height + padding * 2)
                            });
                        }
                    }

                    // Sort top-to-bottom, left-to-right
                    detectedRegions.sort((a, b) => {
                        if (Math.abs(a.y - b.y) < 20) return a.x - b.x;
                        return a.y - b.y;
                    });

                    src.delete(); gray.delete(); binary.delete(); morph.delete(); dilated.delete();
                    kernel.delete(); dilateKernel.delete(); contours.delete(); hierarchy.delete();

                    console.log(`‚úÖ Auto-detected ${detectedRegions.length} text regions`);
                    resolve(detectedRegions);
                } catch (error) {
                    console.error('Auto-detection error:', error);
                    resolve([]);
                }
            });
        };

        // ==================== SMART OCR (HYBRID) ====================
        const performSmartOCR = async (imageDataUrl, userMode, apiKey, onProgress) => {
            // Try Tesseract first
            onProgress?.({ stage: 'tesseract', progress: 0 });

            const tesseractResult = await Tesseract.recognize(imageDataUrl, 'eng', {
                logger: m => {
                    if (m.status === 'recognizing text') {
                        onProgress?.({ stage: 'tesseract', progress: Math.round(m.progress * 100) });
                    }
                },
                tessedit_ocr_engine_mode: Tesseract.OEM.LSTM_ONLY,
                preserve_interword_spaces: '1'
            });

            const rawText = tesseractResult.data.text.trim();
            const cleanedText = postProcessOCRText(rawText);
            const confidence = tesseractResult.data.confidence || 0;

            console.log(`üìù Tesseract: "${cleanedText}" (${confidence.toFixed(1)}%)`);

            // Decide whether to use cloud fallback
            const shouldFallback = (userMode === 'speed') ||
                                   (userMode === 'balanced' && confidence < 60) ||
                                   (confidence < 30);

            if (shouldFallback && apiKey) {
                try {
                    onProgress?.({ stage: 'cloud', progress: 0 });
                    console.log('‚ö° Using cloud API fallback...');

                    const cloudResult = await callGoogleVisionOCR(imageDataUrl, apiKey);
                    onProgress?.({ stage: 'cloud', progress: 100 });

                    console.log(`‚òÅÔ∏è Cloud: "${cloudResult.text}" (${cloudResult.confidence.toFixed(1)}%)`);
                    return { ...cloudResult, method: 'cloud' };
                } catch (error) {
                    console.error('Cloud API error:', error);
                    // Fallback to Tesseract result
                }
            }

            return {
                text: cleanedText,
                confidence: confidence,
                method: 'tesseract'
            };
        };

        // ==================== GOOGLE CLOUD VISION API ====================
        const callGoogleVisionOCR = async (imageDataUrl, apiKey) => {
            const base64Image = imageDataUrl.split(',')[1];

            const response = await fetch(`https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    requests: [{
                        image: { content: base64Image },
                        features: [{ type: 'TEXT_DETECTION', maxResults: 1 }]
                    }]
                })
            });

            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.error?.message || 'Cloud API failed');
            }

            const data = await response.json();
            const annotation = data.responses[0]?.fullTextAnnotation;

            if (!annotation) {
                throw new Error('No text found by Cloud API');
            }

            return {
                text: postProcessOCRText(annotation.text),
                confidence: 98,
                bounds: data.responses[0].textAnnotations?.map(a => a.boundingPoly) || []
            };
        };

        // ==================== MAIN APP ====================
        function App() {
            const [image, setImage] = useState(null);
            const [cvReady, setCvReady] = useState(false);
            const [userMode, setUserMode] = useState('balanced'); // privacy, balanced, speed
            const [apiKey, setApiKey] = useState(localStorage.getItem('gcp_api_key') || '');
            const [showSettings, setShowSettings] = useState(false);

            const [autoDetecting, setAutoDetecting] = useState(false);
            const [detectedRegions, setDetectedRegions] = useState([]);
            const [processingRegion, setProcessingRegion] = useState(null);
            const [results, setResults] = useState([]);

            const canvasRef = useRef(null);
            const imgRef = useRef(null);

            // Check OpenCV
            useEffect(() => {
                const check = setInterval(() => {
                    if (typeof cv !== 'undefined' && cv.Mat) {
                        setCvReady(true);
                        clearInterval(check);
                    }
                }, 100);
                setTimeout(() => clearInterval(check), 30000);
                return () => clearInterval(check);
            }, []);

            // Handle file upload
            const handleFile = (e) => {
                const file = e.target.files[0];
                if (!file) return;
                const reader = new FileReader();
                reader.onload = (ev) => {
                    const img = new Image();
                    img.onload = () => {
                        imgRef.current = img;
                        setImage(ev.target.result);
                        setDetectedRegions([]);
                        setResults([]);
                        drawCanvas(img);
                    };
                    img.src = ev.target.result;
                };
                reader.readAsDataURL(file);
            };

            // Draw canvas
            const drawCanvas = useCallback((img = imgRef.current) => {
                if (!img || !canvasRef.current) return;
                const canvas = canvasRef.current;
                const ctx = canvas.getContext('2d');
                canvas.width = img.naturalWidth;
                canvas.height = img.naturalHeight;
                ctx.drawImage(img, 0, 0);

                // Draw detected regions
                detectedRegions.forEach((region, idx) => {
                    const result = results.find(r => r.id === region.id);
                    const color = result?.confidence >= 70 ? '#10b981' : result?.confidence >= 40 ? '#f59e0b' : '#3b82f6';

                    ctx.strokeStyle = color;
                    ctx.lineWidth = 3;
                    ctx.strokeRect(region.x, region.y, region.width, region.height);

                    // Badge
                    ctx.fillStyle = color;
                    ctx.fillRect(region.x, region.y - 25, 30, 25);
                    ctx.fillStyle = '#fff';
                    ctx.font = 'bold 14px Inter';
                    ctx.textAlign = 'center';
                    ctx.fillText(String(idx + 1), region.x + 15, region.y - 8);

                    // Show text if processed
                    if (result && region.width > 100) {
                        ctx.fillStyle = 'rgba(0,0,0,0.8)';
                        ctx.fillRect(region.x, region.y + region.height, Math.min(region.width, 300), 22);
                        ctx.fillStyle = '#fff';
                        ctx.font = '12px Inter';
                        ctx.textAlign = 'left';
                        const displayText = result.text.length > 35 ? result.text.substring(0, 35) + '...' : result.text;
                        ctx.fillText(displayText, region.x + 5, region.y + region.height + 15);
                    }
                });
            }, [detectedRegions, results]);

            useEffect(() => drawCanvas(), [drawCanvas]);

            // Auto-detect all text
            const handleAutoDetect = async () => {
                if (!image || !cvReady) {
                    alert('Please wait for OpenCV to load!');
                    return;
                }

                setAutoDetecting(true);
                setDetectedRegions([]);
                setResults([]);

                const regions = await autoDetectTextRegions(canvasRef.current, cvReady);

                if (regions.length === 0) {
                    alert('No text regions found. Try uploading a different image.');
                    setAutoDetecting(false);
                    return;
                }

                setDetectedRegions(regions);
                setAutoDetecting(false);

                console.log(`Found ${regions.length} regions, starting OCR...`);
                await processAllRegions(regions);
            };

            // Process all regions
            const processAllRegions = async (regions) => {
                const canvas = canvasRef.current;
                const ctx = canvas.getContext('2d');

                for (let i = 0; i < Math.min(regions.length, 15); i++) {
                    const region = regions[i];
                    setProcessingRegion(i);

                    try {
                        // Extract region
                        const snippet = document.createElement('canvas');
                        snippet.width = region.width;
                        snippet.height = region.height;
                        const snippetCtx = snippet.getContext('2d');
                        snippetCtx.drawImage(canvas, region.x, region.y, region.width, region.height, 0, 0, region.width, region.height);

                        // Preprocess
                        const enhanced = await preprocessImageForOCR(snippet);

                        // Smart OCR
                        const result = await performSmartOCR(
                            enhanced,
                            userMode,
                            apiKey,
                            (progress) => console.log(`Region ${i + 1}: ${progress.stage} ${progress.progress}%`)
                        );

                        setResults(prev => [...prev, {
                            id: region.id,
                            text: result.text,
                            confidence: result.confidence,
                            method: result.method
                        }]);

                        drawCanvas();
                    } catch (error) {
                        console.error(`Error processing region ${i}:`, error);
                    }
                }

                setProcessingRegion(null);
                console.log('‚úÖ All regions processed!');
            };

            // Save API key
            const saveApiKey = () => {
                localStorage.setItem('gcp_api_key', apiKey);
                alert('API key saved!');
                setShowSettings(false);
            };

            return (
                <div className="flex h-screen overflow-hidden bg-slate-950">
                    {/* Sidebar */}
                    <div className="w-96 bg-slate-900 border-r border-slate-800 flex flex-col shadow-2xl">
                        <div className="p-6 border-b border-slate-800">
                            <h1 className="text-2xl font-bold bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent">
                                V5 Hybrid Auto
                            </h1>
                            <p className="text-xs text-slate-500 mt-1">Auto-Detection + Cloud Fallback</p>

                            <div className="mt-4 flex items-center justify-between">
                                <div className="text-xs">
                                    {cvReady ? (
                                        <span className="text-green-400">‚úì OpenCV Ready</span>
                                    ) : (
                                        <span className="text-yellow-400 animate-pulse">‚è≥ OpenCV Loading...</span>
                                    )}
                                </div>
                                <button
                                    onClick={() => setShowSettings(!showSettings)}
                                    className="text-xs px-3 py-1 bg-slate-800 hover:bg-slate-700 rounded transition">
                                    ‚öôÔ∏è Settings
                                </button>
                            </div>

                            {showSettings && (
                                <div className="mt-4 p-4 bg-slate-800 rounded-lg space-y-3 animate-fade-in">
                                    <div>
                                        <label className="text-xs text-slate-400 block mb-1">Mode</label>
                                        <select
                                            value={userMode}
                                            onChange={(e) => setUserMode(e.target.value)}
                                            className="w-full bg-slate-700 text-white text-sm rounded p-2">
                                            <option value="privacy">Privacy (Free, Local Only, 85%)</option>
                                            <option value="balanced">Balanced (Mostly Free, 95%)</option>
                                            <option value="speed">Speed (Paid, 98%)</option>
                                        </select>
                                    </div>

                                    {(userMode === 'balanced' || userMode === 'speed') && (
                                        <div>
                                            <label className="text-xs text-slate-400 block mb-1">Google Cloud API Key</label>
                                            <input
                                                type="password"
                                                value={apiKey}
                                                onChange={(e) => setApiKey(e.target.value)}
                                                placeholder="AIza..."
                                                className="w-full bg-slate-700 text-white text-sm rounded p-2 mb-2"
                                            />
                                            <button
                                                onClick={saveApiKey}
                                                className="w-full text-xs py-1 bg-blue-600 hover:bg-blue-500 rounded transition">
                                                Save API Key
                                            </button>
                                            <p className="text-xs text-slate-500 mt-2">
                                                Get key at: <a href="https://console.cloud.google.com/apis/credentials" target="_blank" className="text-blue-400">Google Cloud Console</a>
                                            </p>
                                        </div>
                                    )}
                                </div>
                            )}
                        </div>

                        {!image ? (
                            <div className="flex-1 flex items-center justify-center p-6">
                                <label className="cursor-pointer flex flex-col items-center justify-center w-full h-64 border-2 border-dashed border-slate-700 rounded-xl hover:bg-slate-800/50 transition">
                                    <input type="file" onChange={handleFile} className="hidden" accept="image/*" />
                                    <div className="text-6xl mb-4">üì∏</div>
                                    <span className="text-slate-400 font-medium">Upload Image</span>
                                    <span className="text-xs text-slate-600 mt-2">JPG, PNG, etc.</span>
                                </label>
                            </div>
                        ) : (
                            <div className="flex-1 flex flex-col overflow-hidden">
                                <div className="p-6 space-y-3">
                                    <button
                                        onClick={handleAutoDetect}
                                        disabled={autoDetecting || !cvReady}
                                        className="w-full py-3 bg-gradient-to-r from-blue-600 to-purple-600 hover:from-blue-500 hover:to-purple-500 text-white font-semibold rounded-lg transition disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2">
                                        {autoDetecting ? (
                                            <>
                                                <div className="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                                                <span>Detecting...</span>
                                            </>
                                        ) : (
                                            <>
                                                <span>üîç</span>
                                                <span>Auto-Detect All Text</span>
                                            </>
                                        )}
                                    </button>

                                    {processingRegion !== null && (
                                        <div className="text-center text-sm text-slate-400">
                                            Processing region {processingRegion + 1} of {detectedRegions.length}...
                                        </div>
                                    )}

                                    <label className="cursor-pointer block w-full py-2 bg-slate-800 hover:bg-slate-700 text-center text-slate-400 text-sm rounded-lg transition">
                                        <input type="file" onChange={handleFile} className="hidden" />
                                        Upload New Image
                                    </label>
                                </div>

                                {/* Results */}
                                {results.length > 0 && (
                                    <div className="flex-1 overflow-y-auto p-6 pt-0">
                                        <h3 className="text-sm font-bold text-slate-400 mb-3">
                                            Detected Text ({results.length})
                                        </h3>
                                        <div className="space-y-2">
                                            {results.map((result, idx) => (
                                                <div key={result.id} className="bg-slate-800 rounded-lg p-3 border border-slate-700">
                                                    <div className="flex items-center justify-between mb-2">
                                                        <span className="text-xs font-bold text-slate-500">#{idx + 1}</span>
                                                        <div className="flex items-center gap-2">
                                                            <span className={'text-xs px-2 py-0.5 rounded ' +
                                                                (result.confidence >= 70 ? 'bg-green-900 text-green-300' :
                                                                 result.confidence >= 40 ? 'bg-yellow-900 text-yellow-300' :
                                                                 'bg-red-900 text-red-300')}>
                                                                {result.confidence.toFixed(0)}%
                                                            </span>
                                                            {result.method === 'cloud' && (
                                                                <span className="text-xs px-2 py-0.5 rounded bg-blue-900 text-blue-300">‚òÅÔ∏è Cloud</span>
                                                            )}
                                                        </div>
                                                    </div>
                                                    <p className="text-sm text-white">{result.text || '(empty)'}</p>
                                                </div>
                                            ))}
                                        </div>

                                        <button
                                            onClick={() => {
                                                const text = results.map((r, i) => `${i + 1}. ${r.text}`).join('\n');
                                                navigator.clipboard.writeText(text);
                                                alert('Copied to clipboard!');
                                            }}
                                            className="w-full mt-4 py-2 bg-green-600 hover:bg-green-500 text-white text-sm font-medium rounded-lg transition">
                                            üìã Copy All Text
                                        </button>
                                    </div>
                                )}
                            </div>
                        )}
                    </div>

                    {/* Canvas */}
                    <div className="flex-1 flex items-center justify-center p-8 bg-slate-950 overflow-auto">
                        {image ? (
                            <canvas ref={canvasRef} className="shadow-2xl max-w-full max-h-full" />
                        ) : (
                            <div className="text-center text-slate-600">
                                <div className="text-6xl mb-4">üëà</div>
                                <p>Upload an image to begin</p>
                            </div>
                        )}
                    </div>
                </div>
            );
        }

        ReactDOM.createRoot(document.getElementById('root')).render(<App />);
    </script>
</body>
</html>
